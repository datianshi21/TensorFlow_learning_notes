{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.81131822  1.48459876  0.06532937]\n",
      " [-2.4427042   0.0992484   0.59122431]]\n",
      "[[-0.81131822]\n",
      " [ 1.48459876]\n",
      " [ 0.06532937]]\n",
      "After 0 training step(s), cross entropy on all data is 0.470155\n",
      "After 1000 training step(s), cross entropy on all data is 0.054546\n",
      "After 2000 training step(s), cross entropy on all data is 0.0293009\n",
      "After 3000 training step(s), cross entropy on all data is 0.0153037\n",
      "After 4000 training step(s), cross entropy on all data is 0.0100591\n",
      "After 5000 training step(s), cross entropy on all data is 0.00823807\n",
      "After 6000 training step(s), cross entropy on all data is 0.00741278\n",
      "After 7000 training step(s), cross entropy on all data is 0.0063658\n",
      "After 8000 training step(s), cross entropy on all data is 0.00516446\n",
      "After 9000 training step(s), cross entropy on all data is 0.00390483\n",
      "After 10000 training step(s), cross entropy on all data is 0.00265029\n",
      "After 11000 training step(s), cross entropy on all data is 0.00144403\n",
      "After 12000 training step(s), cross entropy on all data is 0.00029683\n",
      "After 13000 training step(s), cross entropy on all data is -0\n",
      "After 14000 training step(s), cross entropy on all data is -0\n",
      "After 15000 training step(s), cross entropy on all data is -0\n",
      "After 16000 training step(s), cross entropy on all data is -0\n",
      "After 17000 training step(s), cross entropy on all data is -0\n",
      "After 18000 training step(s), cross entropy on all data is -0\n",
      "After 19000 training step(s), cross entropy on all data is -0\n",
      "[[-0.81131822  4.11521339  3.71558714]\n",
      " [-2.4427042   1.90406477  3.5929153 ]]\n",
      "[[-0.81131822]\n",
      " [ 4.19540119]\n",
      " [ 2.67088747]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))\n",
    "w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2), name=\"x-input\")\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1), name=\"y-input\")\n",
    "\n",
    "a = tf.nn.relu(tf.matmul(x, w1))\n",
    "y = tf.nn.relu(tf.matmul(a, w2))\n",
    "\n",
    "#a = tf.matmul(x, w1)\n",
    "#y = tf.matmul(a, w2)\n",
    "cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "rdm = RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rd.rand(dataset_size, 2)\n",
    "Y = [[int(x1 * x1 * x1 + x2 * x2 * x2 < 100)] for (x1, x2) in X]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variable_initializer()\n",
    "    sess.run(init_op)\n",
    "    sess.run(w1)\n",
    "    sess.run(w2)\n",
    "    STEPS = 20000\n",
    "    for i in range(STEPS):\n",
    "        start = (i * batch_size) % dataset_size\n",
    "        end = min(start + batch_size, dataset_size)\n",
    "        sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]})\n",
    "        \n",
    "cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "rdm = RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size, 2)\n",
    "\n",
    "#Y = [[int(x1 + x2 < 1)] for (x1, x2) in X]\n",
    "Y= [[int(x1 * x1 * x1 + x2 * x2 * x2 < 100)] for (x1, x2) in X]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))\n",
    "\n",
    "    STEPS = 20000\n",
    "    for i in range(STEPS):\n",
    "        start = (i * batch_size) % dataset_size\n",
    "        end = min(start + batch_size, dataset_size)\n",
    "\n",
    "        sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]})\n",
    "        if i % 1000 == 0:\n",
    "            total_cross_entropy = sess.run(cross_entropy, feed_dict={x: X, y_: Y})\n",
    "            print(\"After %d training step(s), cross entropy on all data is %g\" % (i, total_cross_entropy))\n",
    "\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Using activation function relu:\n",
    "[[-0.81131822  1.48459876  0.06532937]\n",
    " [-2.4427042   0.0992484   0.59122431]]\n",
    "[[-0.81131822]\n",
    " [ 1.48459876]\n",
    " [ 0.06532937]]\n",
    "After 0 training step(s), cross entropy on all data is 0.470155\n",
    "After 1000 training step(s), cross entropy on all data is 0.054546\n",
    "After 2000 training step(s), cross entropy on all data is 0.0293009\n",
    "After 3000 training step(s), cross entropy on all data is 0.0153037\n",
    "After 4000 training step(s), cross entropy on all data is 0.0100591\n",
    "After 5000 training step(s), cross entropy on all data is 0.00823807\n",
    "After 6000 training step(s), cross entropy on all data is 0.00741278\n",
    "After 7000 training step(s), cross entropy on all data is 0.0063658\n",
    "After 8000 training step(s), cross entropy on all data is 0.00516446\n",
    "After 9000 training step(s), cross entropy on all data is 0.00390483\n",
    "After 10000 training step(s), cross entropy on all data is 0.00265029\n",
    "After 11000 training step(s), cross entropy on all data is 0.00144403\n",
    "After 12000 training step(s), cross entropy on all data is 0.00029683\n",
    "After 13000 training step(s), cross entropy on all data is -0\n",
    "After 14000 training step(s), cross entropy on all data is -0\n",
    "After 15000 training step(s), cross entropy on all data is -0\n",
    "After 16000 training step(s), cross entropy on all data is -0\n",
    "After 17000 training step(s), cross entropy on all data is -0\n",
    "After 18000 training step(s), cross entropy on all data is -0\n",
    "After 19000 training step(s), cross entropy on all data is -0\n",
    "[[-0.81131822  4.11521339  3.71558714]\n",
    " [-2.4427042   1.90406477  3.5929153 ]]\n",
    "[[-0.81131822]\n",
    " [ 4.19540119]\n",
    " [ 2.67088747]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without using activation function\n",
    "After 0 training step(s), cross entropy on all data is 0.0674925\n",
    "After 1000 training step(s), cross entropy on all data is 0.0163385\n",
    "After 2000 training step(s), cross entropy on all data is 0.00907547\n",
    "After 3000 training step(s), cross entropy on all data is 0.00714436\n",
    "After 4000 training step(s), cross entropy on all data is 0.00578471\n",
    "After 5000 training step(s), cross entropy on all data is 0.00430222\n",
    "After 6000 training step(s), cross entropy on all data is 0.00280812\n",
    "After 7000 training step(s), cross entropy on all data is 0.00137464\n",
    "After 8000 training step(s), cross entropy on all data is 2.11566e-05\n",
    "After 9000 training step(s), cross entropy on all data is -0\n",
    "After 10000 training step(s), cross entropy on all data is -0\n",
    "After 11000 training step(s), cross entropy on all data is -0\n",
    "After 12000 training step(s), cross entropy on all data is -0\n",
    "After 13000 training step(s), cross entropy on all data is -0\n",
    "After 14000 training step(s), cross entropy on all data is -0\n",
    "After 15000 training step(s), cross entropy on all data is -0\n",
    "After 16000 training step(s), cross entropy on all data is -0\n",
    "After 17000 training step(s), cross entropy on all data is -0\n",
    "After 18000 training step(s), cross entropy on all data is -0\n",
    "After 19000 training step(s), cross entropy on all data is -0\n",
    "[[-2.59392238  3.18602753  2.38825655]\n",
    " [-4.1101799   1.6826365   2.83427358]]\n",
    "[[-2.43003726]\n",
    " [ 3.33411145]\n",
    " [ 2.10067439]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
